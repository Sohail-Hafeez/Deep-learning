{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2>20 Newsgroups Dataset Overview</h2>\n",
        "<p>This notebook loads the <strong>20 Newsgroups</strong> dataset, a popular text classification dataset that contains approximately 20,000 newsgroup documents evenly divided across 20 categories.</p>\n",
        "<p>The first code cell performs the following:</p>\n",
        "<ul>\n",
        "  <li>Loads the entire dataset (both training and test parts) using <code>fetch_20newsgroups</code> from <code>sklearn.datasets</code>, removing headers, footers, and quotes for cleaner text data.</li>\n",
        "  <li>Converts the loaded data into a <code>pandas DataFrame</code> with three columns:\n",
        "    <ul>\n",
        "      <li><code>text</code>: the raw newsgroup post content</li>\n",
        "      <li><code>target</code>: the integer label representing the newsgroup category</li>\n",
        "      <li><code>Category</code>: the category name for the 5th target (index 4) — just as an example</li>\n",
        "    </ul>\n",
        "  </li>\n",
        "  <li>Prints the first 5 rows of the DataFrame to give a preview of the dataset structure.</li>\n",
        "</ul>\n"
      ],
      "metadata": {
        "id": "taSNFYhxuAns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbO372--39-A",
        "outputId": "188ab64b-03b6-4b10-a624-8966c6e3f915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  target  \\\n",
            "0  \\n\\nI am sure some bashers of Pens fans are pr...      10   \n",
            "1  My brother is in the market for a high-perform...       3   \n",
            "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...      17   \n",
            "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...       3   \n",
            "4  1)    I have an old Jasmine drive which I cann...       4   \n",
            "\n",
            "                Category  \n",
            "0  comp.sys.mac.hardware  \n",
            "1  comp.sys.mac.hardware  \n",
            "2  comp.sys.mac.hardware  \n",
            "3  comp.sys.mac.hardware  \n",
            "4  comp.sys.mac.hardware  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Load the dataset (all subsets: train + test)\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'text': newsgroups.data,\n",
        "    'target': newsgroups.target,\n",
        "    'Category': newsgroups.target_names[4]\n",
        "})\n",
        "\n",
        "# Show first 5 rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeA1Vq9Z3_f9",
        "outputId": "47bab150-cb45-4317-dc36-134f79c4a8dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18846, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Sf7sEoBc4faJ"
      },
      "outputs": [],
      "source": [
        "# importing the necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Train / Test split"
      ],
      "metadata": {
        "id": "ufwnSizVuXko"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MFwnDFtC609k"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>TF-IDF Vectorization of Text Data</h2>\n",
        "<p>This cell uses <code>TfidfVectorizer</code> from <code>scikit-learn</code> to convert the raw text data into numerical feature vectors that can be fed into a machine learning model.</p>\n",
        "<ul>\n",
        "  <li><strong>max_features=20000</strong>: Limits the vocabulary to the 20,000 most frequent words.</li>\n",
        "  <li><strong>stop_words='english'</strong>: Removes common English stopwords to focus on meaningful words.</li>\n",
        "  <li><strong>lowercase=True</strong>: Converts all text to lowercase for uniformity.</li>\n",
        "  <li><code>fit_transform</code> is applied on training data to learn the vocabulary and transform texts into TF-IDF features.</li>\n",
        "  <li><code>transform</code> is used on test data to convert texts into the same feature space learned from training data.</li>\n",
        "</ul>\n",
        "<p>The output is a dense numpy array representation of TF-IDF features ready for model training.</p>\n"
      ],
      "metadata": {
        "id": "WO-fqukNujAE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JHPjr5cM7Fb0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=20000, stop_words='english', lowercase=True)\n",
        "\n",
        "X_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_vec = vectorizer.transform(X_test).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Neural Network Model Architecture</h2>\n",
        "<p>This cell defines a simple feedforward neural network using <code>TensorFlow Keras</code> with the following layers:</p>\n",
        "<ul>\n",
        "  <li><strong>Input Layer:</strong> Accepts the TF-IDF feature vectors of shape <code>(X_train_vec.shape[1],)</code>.</li>\n",
        "  <li><strong>Dense Layer 1:</strong> 512 neurons with ReLU activation to learn complex patterns.</li>\n",
        "  <li><strong>Dropout Layer 1:</strong> Applies 30% dropout to reduce overfitting.</li>\n",
        "  <li><strong>Dense Layer 2:</strong> 256 neurons with ReLU activation.</li>\n",
        "  <li><strong>Dropout Layer 2:</strong> Another 30% dropout layer.</li>\n",
        "  <li><strong>Output Layer:</strong> 20 neurons with softmax activation corresponding to the 20 newsgroup categories, producing a probability distribution over classes.</li>\n",
        "</ul>\n",
        "<p>This architecture is designed to classify the text data into one of the 20 categories.</p>\n"
      ],
      "metadata": {
        "id": "HMWyFrHAusIK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "26PDPR1t6W3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b23cbb-4f82-483f-994c-f4d6f0c55915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(X_train_vec.shape[1],)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(20, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BNwwtnxX7m8y"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.astype('int')\n",
        "y_test = y_test.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Model Compilation</h2>\n",
        "<p>In this step, we configure the model for training by specifying:</p>\n",
        "<ul>\n",
        "  <li><strong>Optimizer:</strong> <code>Adam</code> with a learning rate of 0.001, which adapts the learning rate during training for efficient convergence.</li>\n",
        "  <li><strong>Loss Function:</strong> <code>sparse_categorical_crossentropy</code> is used because the target labels are integers representing categories (not one-hot encoded).</li>\n",
        "  <li><strong>Metrics:</strong> We track <code>accuracy</code> to monitor the proportion of correctly classified samples during training and validation.</li>\n",
        "</ul>\n"
      ],
      "metadata": {
        "id": "PFtSpkNfu1BP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Cq-zBQGz73UR"
      },
      "outputs": [],
      "source": [
        "# Compile\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Model Training</h2>\n",
        "<p>This cell trains the neural network on the TF-IDF feature vectors with the following settings:</p>\n",
        "<ul>\n",
        "  <li><strong>Training data:</strong> <code>X_train_vec</code> and labels <code>y_train</code>.</li>\n",
        "  <li><strong>Validation data:</strong> <code>X_test_vec</code> and labels <code>y_test</code> to monitor performance on unseen data.</li>\n",
        "  <li><strong>Epochs:</strong> The model will train for 10 full passes over the training dataset.</li>\n",
        "  <li><strong>Batch size:</strong> 32 samples per training update.</li>\n",
        "</ul>\n",
        "<p>The training process outputs a <code>history</code> object containing loss and accuracy metrics to analyze model performance.</p>\n"
      ],
      "metadata": {
        "id": "1SoOyCe3u6k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_vec, y_train,\n",
        "    validation_data=(X_test_vec, y_test),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eky5SaOeNEMc",
        "outputId": "dc2ea487-0d35-4a67-c496-21f48c764720"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4126 - loss: 2.1070 - val_accuracy: 0.7361 - val_loss: 0.9024\n",
            "Epoch 2/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8875 - loss: 0.4197 - val_accuracy: 0.7366 - val_loss: 0.9003\n",
            "Epoch 3/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9555 - loss: 0.1711 - val_accuracy: 0.7332 - val_loss: 1.0077\n",
            "Epoch 4/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9688 - loss: 0.1196 - val_accuracy: 0.7302 - val_loss: 1.0547\n",
            "Epoch 5/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9702 - loss: 0.1111 - val_accuracy: 0.7353 - val_loss: 1.1214\n",
            "Epoch 6/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9679 - loss: 0.1112 - val_accuracy: 0.7334 - val_loss: 1.1307\n",
            "Epoch 7/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9689 - loss: 0.1139 - val_accuracy: 0.7294 - val_loss: 1.1627\n",
            "Epoch 8/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9700 - loss: 0.1037 - val_accuracy: 0.7271 - val_loss: 1.1800\n",
            "Epoch 9/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9689 - loss: 0.1063 - val_accuracy: 0.7276 - val_loss: 1.2488\n",
            "Epoch 10/10\n",
            "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9745 - loss: 0.0900 - val_accuracy: 0.7276 - val_loss: 1.2706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Finally checking the accuracy"
      ],
      "metadata": {
        "id": "GPHdHfl_u_Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_vec, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwGrX3B7NO5s",
        "outputId": "d2b3c9d5-b1a4-47bf-c579-fd666575930e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7202 - loss: 1.3425\n",
            "Test Accuracy: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Predicting the Category of New Text</h2>\n",
        "<p>This cell demonstrates how to use the trained model to classify a new piece of text:</p>\n",
        "<ul>\n",
        "  <li>A sample paragraph about space exploration is defined.</li>\n",
        "  <li>The paragraph is transformed into TF-IDF feature vectors using the previously trained <code>vectorizer</code>, ensuring consistent preprocessing.</li>\n",
        "  <li>The model predicts probabilities for each of the 20 categories.</li>\n",
        "  <li>The category with the highest predicted probability is selected as the model’s prediction.</li>\n",
        "  <li>The predicted category index is mapped back to the actual newsgroup category name for readability.</li>\n",
        "</ul>\n",
        "<p>This shows how your model can be applied to classify unseen text data.</p>\n"
      ],
      "metadata": {
        "id": "ajyo84kpvRrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example new text\n",
        "new_text = [\"Space exploration has made remarkable progress in recent years. With the development of advanced rockets and satellites, scientists are now able to study distant planets and galaxies in unprecedented detail. Many countries are investing heavily in space programs to discover new resources and expand human presence beyond Earth.\"]\n",
        "\n",
        "# Transform using the same vectorizer\n",
        "new_vec = vectorizer.transform(new_text).toarray()\n",
        "\n",
        "# Predict probabilities\n",
        "pred_probs = model.predict(new_vec)\n",
        "\n",
        "# Get predicted class index\n",
        "pred_class = pred_probs.argmax(axis=1)[0]\n",
        "\n",
        "#  Here we are mapping index to category name to see the result\n",
        "pred_category = newsgroups.target_names[pred_class]\n",
        "\n",
        "print(f\"Predicted category: {pred_category}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xc1k7E0OrIK",
        "outputId": "dccd7157-0c55-48a9-82c7-c55c6beeb83f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Predicted category: sci.space\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}